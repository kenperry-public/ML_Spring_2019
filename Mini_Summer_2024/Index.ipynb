{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<html>\n",
    "<p style=\"font-size:32px\"><strong>Classical Machine Learning</strong></p>\n",
    "</html>\n",
    "\n",
    "<html>\n",
    "<p style=\"font-size:26px\"><strong>Week 0</strong></p>\n",
    "</html>\n",
    " \n",
    "\n",
    "**Plan**\n",
    "- Setting up your learning and programming environment\n",
    "\n",
    "\n",
    "**Getting started**\n",
    "- [Setting up your ML environment](Setup_NYU.ipynb)\n",
    "    - [Choosing an ML environment](Choosing_an_ML_Environment_NYU.ipynb)\n",
    "- [Quick intro to the tools](Getting_Started.ipynb)\n",
    "\n",
    "<!--- #include (README.md) --->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 1\n",
    "**Plan**\n",
    "- Motivate Machine Learning\n",
    "- Introduce notation used throughout course\n",
    "- Plan for initial lectures\n",
    "    - *What*: Introduce, motivate a model\n",
    "    - *How*:  How to use a model: function signature, code (API)\n",
    "    - *Why*:  Mathematical basis -- enhance understanding and ability to improve results\n",
    "\n",
    "- [Machine Learning: Overview](ML_Overview.ipynb)\n",
    "- [Intro to Classical ML](Intro_Classical_ML.ipynb)\n",
    "\n",
    "\n",
    "**Plan**\n",
    "- Introduce a model for the Regression task: Linear Regression\n",
    "- Introduce the Recipe for Machine Learning: detailed steps to problem solving\n",
    "\n",
    "\n",
    "- [Our first model: Linear Regression (Overview)](Linear_Regression_Overview.ipynb)\n",
    "- A *process* for Machine Learning\n",
    "    - Go through the methodical, multi-step process\n",
    "        - Quick first pass, followed by Deeper Dives\n",
    "    - This will be a code-heavy notebook !\n",
    "    - Illustrate Pandas, Jupyter, etc\n",
    "    \n",
    "## Regression task and a Recipe for Machine Learning\n",
    "\n",
    "**The Recipe for Machine Learning, illustrated with the Linear Regression model**  \n",
    "- [Recipe for Machine Learning: Overview](Recipe_Overview.ipynb)\n",
    "    - [Linked notebook](Recipe_for_ML.ipynb)\n",
    "    \n",
    "\n",
    "**Fitting a model: details**\n",
    "\n",
    "Recall: fitting a model (finding optimal value for the parameters) is found by minimizing a Loss function.\n",
    "\n",
    "Let's examine a typical Loss function for Regression\n",
    "- [Regression: Loss Function](Linear_Regression_Loss_Function.ipynb)\n",
    "\n",
    "Increasing the number of parameters of a model improves in-sample fit (reduces Loss) but may compromise\n",
    "out-of-sample prediction (generalization).\n",
    "\n",
    "We examine the issues of having too many/too few parameters.\n",
    "- [When to stop iterating: Bias and Variance](Bias_and_Variance.ipynb)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 2\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "## Classification Task\n",
    "\n",
    "**Plan**\n",
    "- We introduce a model for the Classification task: Logistic Regression\n",
    "- How to deal with Categorical (non-numeric) variables\n",
    "    - classification target\n",
    "    - features\n",
    "\n",
    "**Classification intro**\n",
    "- [Classification: Overview](Classification_Overview.ipynb)\n",
    "- [Classification and Categorical Variables](Classification_Notebook_Overview.ipynb)\n",
    "    - [linked notebook](Classification_and_Non_Numerical_Data.ipynb)\n",
    "    \n",
    "**Multinomial Classification**\n",
    "\n",
    "- [Multinomial Classification](Multinomial_Classification.ipynb)\n",
    "\n",
    "**Classification and Categorical variables wrapup**\n",
    "\n",
    "- [Classification Loss Function](Classification_Loss_Function.ipynb)\n",
    "- [Baseline model for Classification](Classification_Baseline_Model.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<html>\n",
    "<p style=\"font-size:32px\"><strong>Deep Learning</strong></p>\n",
    "</html>\n",
    "\n",
    "# Week 3\n",
    "\n",
    "## Introduction to Neural Networks and Deep Learning\n",
    "\n",
    "**Plan**\n",
    "\n",
    "Deep Learning/Neural networks\n",
    "\n",
    "- [Set up your Tensorflow environment](Tensorflow_setup.ipynb)\n",
    "- [Neural Networks Overview](Neural_Networks_Overview.ipynb)\n",
    "\n",
    "\n",
    "**Neural network: practical**\n",
    "- Coding Neural Networks: Tensorflow, Keras\n",
    "    - [Intro to Keras](Tensorflow_Keras.ipynb)\n",
    "\n",
    "    - **Note**\n",
    "        - If you have problems using the `plot_model` function in Keras on your local machine: see [here](Setup_ML_Environment_NYU.ipynb#Tools-for-visualization-of-graphs-(optional)) for a fix.\n",
    "\n",
    "    - Linked notebooks\n",
    "        - [DNN Tensorflow example Notebook local](DNN_TensorFlow_example.ipynb) **(local machine)**\n",
    "        - [DNN Tensorflow example Notebook from github](https://colab.research.google.com/github/kenperry-public/ML_Spring_2024/blob/master/DNN_TensorFlow_example.ipynb) (**Google Colab**)\n",
    "\n",
    "\n",
    "- Practical Colab\n",
    "<!--- The Colab notebook imports some modules; make sure they are in the repo --->\n",
    "<!--- #include (neural_net_helper.py) --->\n",
    "<!--- The Colab notebook imports some modules; make sure they are in the repo --->\n",
    "<!--- #include (Colab_practical.ipynb)) --->\n",
    "<!--- #include (CommonLib.py) --->\n",
    "   - **Colab**: [Practical Colab Notebook from github](https://colab.research.google.com/github/kenperry-public/ML_Spring_2024/blob/master/Colab_practical.ipynb)\n",
    "   \n",
    "**Practical advice**\n",
    "\n",
    "- Karpathy: [Recipe for training Neural Nets](Karpathy_Recipe_for_training_NN.ipynb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 4\n",
    "\n",
    "## Limits and Dangers of Neural Networks\n",
    "\n",
    "**What is a Neural Network really doing ? Interpretation**\n",
    "- [Introduction to Interpretation of Deep Learning](Intro_to_Interpretation_of_DL.ipynb)\n",
    "- [interpretation: Gradient Ascent](Gradient_ascent.ipynb)\n",
    "- [Adversarial Examples](Adversarial_Examples.ipynb)\n",
    "\n",
    "## Project presentations\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
